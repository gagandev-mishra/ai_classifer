{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A blue electric minibus with \"cero emisiones\" (zero emissions) written on its side.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "import base64\n",
    "\n",
    "load_dotenv(\".\\.env\")\n",
    "\n",
    "image_path = r\"D:\\Learning Materials\\Data Science\\Projects\\ai-classifier-app\\bus.jpg\"\n",
    "# Open the file in binary mode and encode\n",
    "with open(image_path, \"rb\") as f:\n",
    "    image_bytes = f.read()\n",
    "    image_base64 = base64.b64encode(image_bytes).decode(\"utf-8\")\n",
    "\n",
    "model = ChatGoogleGenerativeAI(\n",
    "            model=\"models/gemini-2.0-flash-exp-image-generation\",\n",
    "            temperature=0,\n",
    "            max_tokens=None,\n",
    "            timeout=None)\n",
    "\n",
    "message = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [\n",
    "        {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": \"What is the main object of this image? just give concise statement \"\n",
    "            \"which I'll use in next agent for generating someusful information\",\n",
    "        },\n",
    "   {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\"url\": f\"data:image/png;base64,{image_base64}\"},\n",
    "        },\n",
    "    ],\n",
    "}\n",
    "\n",
    "response = model.invoke([message],\n",
    "    generation_config=dict(response_modalities=[\"IMAGE\", \"TEXT\"]),\n",
    ") \n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here are the 5 objects detected in the image:\\n\\n1. **Bus**\\n2. **Man with sunglasses and black coat**\\n3. **Man with sunglasses and beige coat**\\n4. **Man walking away (partially visible)**\\n5. **Street/Sidewalk**'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "import base64\n",
    "\n",
    "load_dotenv(\".\\.env\")\n",
    "\n",
    "def short_info_of_image(image_path):\n",
    "    path = image_path\n",
    "    # Open the file in binary mode and encode\n",
    "    with open(path, \"rb\") as f:\n",
    "        image_bytes = f.read()\n",
    "        image_base64 = base64.b64encode(image_bytes).decode(\"utf-8\")\n",
    "\n",
    "    model = ChatGoogleGenerativeAI(\n",
    "                model=\"models/gemini-2.0-flash-exp-image-generation\",\n",
    "                temperature=0,\n",
    "                max_tokens=None,\n",
    "                timeout=None)\n",
    "\n",
    "    message = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"Just detect all the 5 objects in the image \"\n",
    "                \"which I'll use in next agent for generating someusful information\",\n",
    "            },\n",
    "    {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\"url\": f\"data:image/png;base64,{image_base64}\"},\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    response = model.invoke([message],\n",
    "        generation_config=dict(response_modalities=[\"IMAGE\", \"TEXT\"]),\n",
    "    ) \n",
    "    return response.content\n",
    "\n",
    "pa = r\"D:\\Learning Materials\\Data Science\\Projects\\ai-classifier-app\\bus.jpg\"\n",
    "short_info_of_image(pa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here are a few caption options, playing on different aspects of the image description:\\n\\n**Short & Sweet:**\\n\\n*   City life: Bus, coats, and a disappearing act.\\n\\n**More Descriptive:**\\n\\n*   Sunglasses, coats, and the rhythm of the city. A snapshot of everyday moments.\\n\\n**Intriguing:**\\n\\n*   Who's watching whom? A glimpse of urban anonymity.\\n\\n**My Choice (Best):**\\n\\n*   **A stylish street scene: Bus, coats, and the quiet drama of a city sidewalk.**\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "\n",
    "text_model = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash-lite\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None)\n",
    "\n",
    "def generate_funny_message(description: str) -> str:\n",
    "    prompt = f\"Make a short, caption based on this image description: '{description} give one of the best capation out from the image'.\"\n",
    "    response = text_model.invoke([HumanMessage(content=prompt)])\n",
    "    return response.content\n",
    "\n",
    "\n",
    "generate_funny_message(short_info_of_image(pa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "\n",
    "# Step 1: Define state schema\n",
    "class GraphState(TypedDict):\n",
    "    image_base64: str\n",
    "    description: str\n",
    "    funny_message: str\n",
    "\n",
    "def build_image_graph():\n",
    "    graph = StateGraph()\n",
    "\n",
    "    # Agent 01\n",
    "    def image_reader_node(state):\n",
    "        image_bytes = state['image']\n",
    "        description = short_info_of_image(image_bytes)\n",
    "        return description\n",
    "\n",
    "    # Agent 02\n",
    "    def funny_meme_maker(state):\n",
    "        description = state[\"description\"]\n",
    "        message = generate_funny_message(description)\n",
    "        return {\"funny_message\": message}\n",
    "\n",
    "# Add node\n",
    "    graph.add_node(\"describe_image\", image_reader_node)\n",
    "    graph.add_node(\"info_generator\", funny_meme_maker)\n",
    "\n",
    "# Define flow\n",
    "    graph.set_entry_point(\"describe_image\")\n",
    "    graph.add_edge(\"describe_image\", \"make_joke\")\n",
    "    graph.set_finish_point(\"make_joke\")\n",
    "\n",
    "    return graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description: Bus\n",
      "Funny Message: My therapist told me to embrace my mistakes... so I hopped on the wrong bus.\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from typing import TypedDict\n",
    "import base64\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Step 1: Define state schema\n",
    "class GraphState(TypedDict):\n",
    "    image_base64: str\n",
    "    description: str\n",
    "    funny_message: str\n",
    "\n",
    "# Step 2: Node to describe the image\n",
    "def image_reader_node(state: GraphState) -> dict:\n",
    "    model = ChatGoogleGenerativeAI(model=\"models/gemini-2.0-flash-exp-image-generation\", temperature=0.2)\n",
    "\n",
    "    message = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"What is the main object in this image? Respond with just a noun like 'cat' or 'bus'.\",\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\"url\": f\"data:image/jpeg;base64,{state['image_base64']}\"},\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    response = model.invoke([message])\n",
    "    return {\"description\": response.content.strip()}\n",
    "\n",
    "# Step 3: Node to generate a funny message\n",
    "def funny_maker_node(state: GraphState) -> dict:\n",
    "    model = ChatGoogleGenerativeAI(model=\"models/gemini-1.5-pro-latest\", temperature=0.8)\n",
    "    \n",
    "    prompt = f\"Create a short, funny caption involving a {state['description']}, only 1 caption give without saying 'Here' or something.\"\n",
    "    response = model.invoke(prompt)\n",
    "    \n",
    "    return {\"funny_message\": response.content.strip()}\n",
    "\n",
    "# Step 4: Define and compile graph\n",
    "def build_graph():\n",
    "    graph = StateGraph(GraphState)\n",
    "\n",
    "    graph.add_node(\"describe_image\", image_reader_node)\n",
    "    graph.add_node(\"make_joke\", funny_maker_node)\n",
    "\n",
    "    graph.set_entry_point(\"describe_image\")\n",
    "    graph.add_edge(\"describe_image\", \"make_joke\")\n",
    "    graph.set_finish_point(\"make_joke\")\n",
    "\n",
    "    return graph.compile()\n",
    "\n",
    "\n",
    "import base64\n",
    "\n",
    "# Load image and convert to base64\n",
    "with open(pa, \"rb\") as f:\n",
    "    image_base64 = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "\n",
    "# Run the graph\n",
    "graph = build_graph()\n",
    "final_state = graph.invoke({\"image_base64\": image_base64})\n",
    "\n",
    "print(\"Description:\", final_state[\"description\"])\n",
    "print(\"Funny Message:\", final_state[\"funny_message\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbase64\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Load image and convert to base64\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[43mpa\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      5\u001b[0m     image_base64 \u001b[38;5;241m=\u001b[39m base64\u001b[38;5;241m.\u001b[39mb64encode(f\u001b[38;5;241m.\u001b[39mread())\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Run the graph\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pa' is not defined"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "\n",
    "# Load image and convert to base64\n",
    "with open(pa, \"rb\") as f:\n",
    "    image_base64 = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "\n",
    "# Run the graph\n",
    "graph = build_graph()\n",
    "final_state = graph.invoke({\"image_base64\": image_base64})\n",
    "\n",
    "print(\"Description:\", final_state[\"description\"])\n",
    "print(\"Funny Message:\", final_state[\"funny_message\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
